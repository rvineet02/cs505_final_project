{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "file_path = \"./data/feedback_scores/train.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_id        3911\n",
       "full_text      3911\n",
       "cohesion          9\n",
       "syntax            9\n",
       "vocabulary        9\n",
       "phraseology       9\n",
       "grammar           9\n",
       "conventions       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique values does each column have?\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohesion\n",
      "3.0    1096\n",
      "3.5     988\n",
      "2.5     790\n",
      "4.0     534\n",
      "2.0     315\n",
      "4.5     125\n",
      "1.5      27\n",
      "5.0      26\n",
      "1.0      10\n",
      "Name: count, dtype: int64\n",
      "syntax\n",
      "3.0    1250\n",
      "3.5     867\n",
      "2.5     839\n",
      "2.0     410\n",
      "4.0     388\n",
      "4.5     100\n",
      "1.5      29\n",
      "5.0      17\n",
      "1.0      11\n",
      "Name: count, dtype: int64\n",
      "vocabulary\n",
      "3.0    1503\n",
      "3.5    1007\n",
      "4.0     577\n",
      "2.5     528\n",
      "2.0     124\n",
      "4.5     115\n",
      "5.0      41\n",
      "1.5      14\n",
      "1.0       2\n",
      "Name: count, dtype: int64\n",
      "phraseology\n",
      "3.0    1153\n",
      "3.5     929\n",
      "2.5     772\n",
      "4.0     553\n",
      "2.0     350\n",
      "4.5     108\n",
      "5.0      25\n",
      "1.5      11\n",
      "1.0      10\n",
      "Name: count, dtype: int64\n",
      "grammar\n",
      "3.0    994\n",
      "3.5    880\n",
      "2.5    855\n",
      "2.0    544\n",
      "4.0    447\n",
      "4.5    134\n",
      "5.0     29\n",
      "1.5     20\n",
      "1.0      8\n",
      "Name: count, dtype: int64\n",
      "conventions\n",
      "3.0    1151\n",
      "3.5     908\n",
      "2.5     784\n",
      "4.0     484\n",
      "2.0     402\n",
      "4.5     122\n",
      "5.0      25\n",
      "1.5      20\n",
      "1.0      15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# finding the count of each unique value in a column\n",
    "for col in df.columns[2:]:\n",
    "\t\tprint(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohesion [3.5 2.5 3.  4.5 4.  2.  1.  5.  1.5]\n",
      "syntax [3.5 2.5 4.5 3.  4.  2.  1.  1.5 5. ]\n",
      "vocabulary [3.  4.5 4.  3.5 2.5 2.  5.  1.5 1. ]\n",
      "phraseology [3.  2.  4.5 3.5 2.5 4.  5.  1.5 1. ]\n",
      "grammar [4.  2.  3.  2.5 3.5 4.5 5.  1.5 1. ]\n",
      "conventions [3.  2.5 5.  4.  2.  3.5 4.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "# list all unique values in ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "for col in ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']:\n",
    "\t\tprint(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at the dataset, here there are two things I can do, either I can classify into the 9 buckets that each of the scores has. Or, I can do a regression and move into the closest score to the predicted regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\\n\\nmost students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\\n\\nwhen your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scores into categorical variables of 0, 1, 2, 3, 4, etc for the number of unique values in each score column \n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "\n",
    "# df['cohesion'] = le.fit_transform(df['cohesion'])\n",
    "# df['syntax'] = le.fit_transform(df['syntax'])\n",
    "# df['vocabulary'] = le.fit_transform(df['vocabulary'])\n",
    "# df['phraseology'] = le.fit_transform(df['phraseology'])\n",
    "# df['grammar'] = le.fit_transform(df['grammar'])\n",
    "# df['conventions'] = le.fit_transform(df['conventions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[3.5, 3.5, 3.0, 3.0, 4.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[2.5, 2.5, 3.0, 2.0, 2.0, 2.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[3.0, 3.5, 3.0, 3.0, 3.0, 2.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[4.5, 4.5, 4.5, 4.5, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[2.5, 3.0, 3.0, 3.0, 2.5, 2.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0   \n",
       "1     2.5         3.0          2.0      2.0          2.5   \n",
       "2     3.5         3.0          3.0      3.0          2.5   \n",
       "3     4.5         4.5          4.5      4.0          5.0   \n",
       "4     3.0         3.0          3.0      2.5          2.5   \n",
       "\n",
       "                           scores  \n",
       "0  [3.5, 3.5, 3.0, 3.0, 4.0, 3.0]  \n",
       "1  [2.5, 2.5, 3.0, 2.0, 2.0, 2.5]  \n",
       "2  [3.0, 3.5, 3.0, 3.0, 3.0, 2.5]  \n",
       "3  [4.5, 4.5, 4.5, 4.5, 4.0, 5.0]  \n",
       "4  [2.5, 3.0, 3.0, 3.0, 2.5, 2.5]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the 6 columns into 1 column with a list of 6 values\n",
    "df['scores'] = df[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].values.tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 6 columns\n",
    "df = df.drop(columns=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>[3.5, 3.5, 3.0, 3.0, 4.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>[2.5, 2.5, 3.0, 2.0, 2.0, 2.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>[3.0, 3.5, 3.0, 3.0, 3.0, 2.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>[4.5, 4.5, 4.5, 4.5, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>[2.5, 3.0, 3.0, 3.0, 2.5, 2.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004AC288D833</td>\n",
       "      <td>Dear Principal,\\r\\n\\r\\nOur school should have ...</td>\n",
       "      <td>[3.5, 4.0, 4.0, 3.5, 3.5, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005661280443</td>\n",
       "      <td>Imagine if you could prove other people that y...</td>\n",
       "      <td>[3.5, 4.0, 3.5, 3.5, 4.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>008DDDDD8E8D</td>\n",
       "      <td>I think it's a good idea for the estudnets to ...</td>\n",
       "      <td>[2.5, 2.5, 2.5, 2.5, 2.5, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>009BCCC61C2A</td>\n",
       "      <td>positive attitude is the key to success. I agr...</td>\n",
       "      <td>[3.0, 3.0, 3.5, 3.5, 3.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>009F4E9310CB</td>\n",
       "      <td>Asking more than one person for and advice hel...</td>\n",
       "      <td>[3.0, 3.0, 3.5, 2.5, 3.0, 2.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
       "3  003885A45F42  The best time in life is when you become yours...   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "5  004AC288D833  Dear Principal,\\r\\n\\r\\nOur school should have ...   \n",
       "6  005661280443  Imagine if you could prove other people that y...   \n",
       "7  008DDDDD8E8D  I think it's a good idea for the estudnets to ...   \n",
       "8  009BCCC61C2A  positive attitude is the key to success. I agr...   \n",
       "9  009F4E9310CB  Asking more than one person for and advice hel...   \n",
       "\n",
       "                           scores  \n",
       "0  [3.5, 3.5, 3.0, 3.0, 4.0, 3.0]  \n",
       "1  [2.5, 2.5, 3.0, 2.0, 2.0, 2.5]  \n",
       "2  [3.0, 3.5, 3.0, 3.0, 3.0, 2.5]  \n",
       "3  [4.5, 4.5, 4.5, 4.5, 4.0, 5.0]  \n",
       "4  [2.5, 3.0, 3.0, 3.0, 2.5, 2.5]  \n",
       "5  [3.5, 4.0, 4.0, 3.5, 3.5, 4.0]  \n",
       "6  [3.5, 4.0, 3.5, 3.5, 4.0, 4.0]  \n",
       "7  [2.5, 2.5, 2.5, 2.5, 2.5, 2.0]  \n",
       "8  [3.0, 3.0, 3.5, 3.5, 3.0, 3.0]  \n",
       "9  [3.0, 3.0, 3.5, 2.5, 3.0, 2.5]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Custom Dataset and, Dataloader for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vineetraju/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: M1 GPU\n"
     ]
    }
   ],
   "source": [
    "# set up the GPU\n",
    "APPLE_M1_FLAG=1\n",
    "\n",
    "device = None\n",
    "if APPLE_M1_FLAG:\n",
    "\t# try to setup M1 GPU\n",
    "\tis_gpu = torch.backends.mps.is_available()\n",
    "\tif is_gpu:\n",
    "\t\tdevice = torch.device(\"mps\")\n",
    "\t\tprint(\"DEVICE: M1 GPU\")\n",
    "\telse:\n",
    "\t\tdevice = torch.device(\"cpu\")\n",
    "\t\tprint(\"DEVICE: CPU\")\n",
    "else:\n",
    "\t# use GPU if available\n",
    "\tif torch.cuda.is_available():       \n",
    "\t\tdevice = torch.device(\"cuda\")\n",
    "\t\tprint(\"DEVICE: GPU\")\n",
    "\telse:\n",
    "\t\tdevice = torch.device(\"cpu\")\n",
    "\t\tprint(\"DEVICE: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, dataframe, tokenizer, max_len):\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.data = dataframe\n",
    "\t\tself.full_text = dataframe.full_text\n",
    "\t\tself.targets = self.data.scores\n",
    "\t\tself.max_len = max_len\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.full_text)\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tfull_text = str(self.full_text[index])\n",
    "\t\tfull_text = \" \".join(full_text.split())\n",
    "\n",
    "\t\tinputs = self.tokenizer.encode_plus(\n",
    "\t\t\tfull_text,\n",
    "\t\t\tNone,\n",
    "\t\t\tadd_special_tokens=True,\n",
    "\t\t\tmax_length=self.max_len,\n",
    "\t\t\tpadding='max_length',\n",
    "\t\t\ttruncation=True,\n",
    "\t\t\treturn_token_type_ids=True\n",
    "\t\t)\n",
    "\n",
    "\t\tids = inputs['input_ids']\n",
    "\t\tmask = inputs['attention_mask']\n",
    "\t\ttoken_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'ids': torch.LongTensor(ids),\n",
    "\t\t\t'mask': torch.LongTensor(mask),\n",
    "\t\t\t'token_type_ids': torch.LongTensor(token_type_ids),\n",
    "\t\t\t'targets': torch.LongTensor(self.targets[index])\n",
    "\t\t}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### HYPERPARAMETERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (3911, 3)\n",
      "TRAIN Dataset: (1173, 3)\n",
      "TEST Dataset: (2738, 3)\n"
     ]
    }
   ],
   "source": [
    "# creating the dataset and the dataloader\n",
    "train_size = 0.8\n",
    "\n",
    "print(f\"FULL Dataset: {df.shape}\")\n",
    "\n",
    "train_ds = df.sample(frac=train_size, random_state=200)\n",
    "test_ds = df.drop(train_ds.index).reset_index(drop=True)\n",
    "train_ds = train_ds.reset_index(drop=True)\n",
    "\n",
    "print(f\"TRAIN Dataset: {train_ds.shape}\")\n",
    "print(f\"TEST Dataset: {test_ds.shape}\")\n",
    "\n",
    "train_set = CustomDataset(train_ds, tokenizer, MAX_LEN)\n",
    "test_set = CustomDataset(test_ds, tokenizer, MAX_LEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "\t\t\t\t'shuffle': True,\n",
    "\t\t\t\t'num_workers': 0\n",
    "\t\t\t\t}\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "\t\t\t\t'shuffle': True,\n",
    "\t\t\t\t'num_workers': 0\n",
    "\t\t\t\t}\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Classifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.0, inplace=False)\n",
       "  (out): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "class BERT_Classifier(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(BERT_Classifier, self).__init__()\n",
    "\t\tself.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\t\tself.drop = nn.Dropout(0.0)\n",
    "\t\tself.out = nn.Linear(768, 6)\n",
    "\t\t\n",
    "\n",
    "\tdef forward (self, ids, mask, token_type_ids):\n",
    "\t\t_, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "\t\toutput_2 = self.drop(pooled_output)\n",
    "\t\toutput = self.out(output_2)\n",
    "\t\treturn output\n",
    "\t\n",
    "model = BERT_Classifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the Model work?\n",
    "\n",
    "- We are using the BERT model. We then added a `Dropout` and `Linear Layer` as well. We add these layers to ensure the model is able to regularize and classify the data better.\n",
    "\n",
    "- In the forward loop, there are 2 outputs from the `BERT` model layer. \n",
    "\n",
    "- The output of this, `pooled_output` is passed through the `Dropout` layer and then the `Linear` layer.\n",
    "\n",
    "- We set the number of dimesnions in the `Linear` layer to be equal to the number of classes we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "\treturn nn.MSELoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\tmodel.train()\n",
    "\tfor idx, data in enumerate(train_loader, 0):\n",
    "\t\tids = data['ids'].to(device, dtype=torch.long)\n",
    "\t\tmask = data['mask'].to(device, dtype=torch.long)\n",
    "\t\ttoken_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "\t\ttargets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(ids, mask, token_type_ids)\n",
    "\t\tloss = loss_fn(outputs, targets)\n",
    "\t\tif idx % 100 == 0:\n",
    "\t\t\tprint(f\"Batch: {idx} | Loss: {loss.item()}\")\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\n",
    "\tprint(f\"EPOCH: {epoch} | LOSS: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0 | Loss: 2.0698037147521973\n",
      "Batch: 100 | Loss: 0.4164322018623352\n",
      "EPOCH: 0 | LOSS: 0.30708202719688416\n",
      "Batch: 0 | Loss: 0.3629642724990845\n",
      "Batch: 100 | Loss: 0.3170408010482788\n",
      "EPOCH: 1 | LOSS: 0.3164137005805969\n",
      "Batch: 0 | Loss: 0.2466357946395874\n",
      "Batch: 100 | Loss: 0.31148561835289\n",
      "EPOCH: 2 | LOSS: 0.33257877826690674\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\ttrain(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "\tmodel.eval()\n",
    "\tfin_targets = []\n",
    "\tfin_outputs = []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor _, data in enumerate(test_loader, 0):\n",
    "\t\t\tids = data['ids'].to(device, dtype=torch.long)\n",
    "\t\t\tmask = data['mask'].to(device, dtype=torch.long)\n",
    "\t\t\ttoken_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "\t\t\ttargets = data['targets'].to(device, dtype=torch.long)\n",
    "\t\t\toutputs = model(ids, mask, token_type_ids)\n",
    "\t\t\tfin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "\t\t\tfin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\t\t\t# fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\treturn fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(outputs, targets):\n",
    "\t# compute the mean squared error between the actual and predicted scores\n",
    "\tmse = metrics.mean_squared_error(targets, outputs)\n",
    "\treturn mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.392521858215332, 3.2922492027282715, 3.4225714206695557, 3.5249059200286865, 3.3607194423675537, 3.3364408016204834] [3, 2, 3, 2, 2, 3]\n",
      "EPOCH: 0 | ACCURACY: None\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\toutputs, targets = validation(epoch=epoch)\n",
    "\tmse = calculate_metrics(outputs, targets)\n",
    "\tprint(f\"EPOCH: {epoch} | MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
