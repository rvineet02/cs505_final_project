{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "file_path = \"./data/feedback_scores/train.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_id        3911\n",
       "full_text      3911\n",
       "cohesion          9\n",
       "syntax            9\n",
       "vocabulary        9\n",
       "phraseology       9\n",
       "grammar           9\n",
       "conventions       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique values does each column have?\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohesion [3.5 2.5 3.  4.5 4.  2.  1.  5.  1.5]\n",
      "syntax [3.5 2.5 4.5 3.  4.  2.  1.  1.5 5. ]\n",
      "vocabulary [3.  4.5 4.  3.5 2.5 2.  5.  1.5 1. ]\n",
      "phraseology [3.  2.  4.5 3.5 2.5 4.  5.  1.5 1. ]\n",
      "grammar [4.  2.  3.  2.5 3.5 4.5 5.  1.5 1. ]\n",
      "conventions [3.  2.5 5.  4.  2.  3.5 4.5 1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "# list all unique values in ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "for col in ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']:\n",
    "\t\tprint(col, df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at the dataset, here there are two things I can do, either I can classify into the 9 buckets that each of the scores has. Or, I can do a regression and move into the closest score to the predicted regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scores into categorical variables of 0, 1, 2, 3, 4, etc for the number of unique values in each score column \n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df['cohesion'] = le.fit_transform(df['cohesion'])\n",
    "df['syntax'] = le.fit_transform(df['syntax'])\n",
    "df['vocabulary'] = le.fit_transform(df['vocabulary'])\n",
    "df['phraseology'] = le.fit_transform(df['phraseology'])\n",
    "df['grammar'] = le.fit_transform(df['grammar'])\n",
    "df['conventions'] = le.fit_transform(df['conventions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 5, 4, 4, 6, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 3, 4, 2, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 5, 4, 4, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>[7, 7, 7, 7, 6, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 4, 4, 4, 3, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...         5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...         3   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...         4   \n",
       "3  003885A45F42  The best time in life is when you become yours...         7   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...         3   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions              scores  \n",
       "0       5           4            4        6            4  [5, 5, 4, 4, 6, 4]  \n",
       "1       3           4            2        2            3  [3, 3, 4, 2, 2, 3]  \n",
       "2       5           4            4        4            3  [4, 5, 4, 4, 4, 3]  \n",
       "3       7           7            7        6            8  [7, 7, 7, 7, 6, 8]  \n",
       "4       4           4            4        3            3  [3, 4, 4, 4, 3, 3]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the 6 columns into 1 column with a list of 6 values\n",
    "df['scores'] = df[['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].values.tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 6 columns\n",
    "df = df.drop(columns=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>[5, 5, 4, 4, 6, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>[3, 3, 4, 2, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>[4, 5, 4, 4, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>[7, 7, 7, 7, 6, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>[3, 4, 4, 4, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004AC288D833</td>\n",
       "      <td>Dear Principal,\\r\\n\\r\\nOur school should have ...</td>\n",
       "      <td>[5, 6, 6, 5, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005661280443</td>\n",
       "      <td>Imagine if you could prove other people that y...</td>\n",
       "      <td>[5, 6, 5, 5, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>008DDDDD8E8D</td>\n",
       "      <td>I think it's a good idea for the estudnets to ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>009BCCC61C2A</td>\n",
       "      <td>positive attitude is the key to success. I agr...</td>\n",
       "      <td>[4, 4, 5, 5, 4, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>009F4E9310CB</td>\n",
       "      <td>Asking more than one person for and advice hel...</td>\n",
       "      <td>[4, 4, 5, 3, 4, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
       "3  003885A45F42  The best time in life is when you become yours...   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "5  004AC288D833  Dear Principal,\\r\\n\\r\\nOur school should have ...   \n",
       "6  005661280443  Imagine if you could prove other people that y...   \n",
       "7  008DDDDD8E8D  I think it's a good idea for the estudnets to ...   \n",
       "8  009BCCC61C2A  positive attitude is the key to success. I agr...   \n",
       "9  009F4E9310CB  Asking more than one person for and advice hel...   \n",
       "\n",
       "               scores  \n",
       "0  [5, 5, 4, 4, 6, 4]  \n",
       "1  [3, 3, 4, 2, 2, 3]  \n",
       "2  [4, 5, 4, 4, 4, 3]  \n",
       "3  [7, 7, 7, 7, 6, 8]  \n",
       "4  [3, 4, 4, 4, 3, 3]  \n",
       "5  [5, 6, 6, 5, 5, 6]  \n",
       "6  [5, 6, 5, 5, 6, 6]  \n",
       "7  [3, 3, 3, 3, 3, 2]  \n",
       "8  [4, 4, 5, 5, 4, 4]  \n",
       "9  [4, 4, 5, 3, 4, 3]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Custom Dataset and, Dataloader for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vineetraju/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: M1 GPU\n"
     ]
    }
   ],
   "source": [
    "# set up the GPU\n",
    "APPLE_M1_FLAG=1\n",
    "\n",
    "device = None\n",
    "if APPLE_M1_FLAG:\n",
    "\t# try to setup M1 GPU\n",
    "\tis_gpu = torch.backends.mps.is_available()\n",
    "\tif is_gpu:\n",
    "\t\tdevice = torch.device(\"mps\")\n",
    "\t\tprint(\"DEVICE: M1 GPU\")\n",
    "\telse:\n",
    "\t\tdevice = torch.device(\"cpu\")\n",
    "\t\tprint(\"DEVICE: CPU\")\n",
    "else:\n",
    "\t# use GPU if available\n",
    "\tif torch.cuda.is_available():       \n",
    "\t\tdevice = torch.device(\"cuda\")\n",
    "\t\tprint(\"DEVICE: GPU\")\n",
    "\telse:\n",
    "\t\tdevice = torch.device(\"cpu\")\n",
    "\t\tprint(\"DEVICE: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, dataframe, tokenizer, max_len):\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.data = dataframe\n",
    "\t\tself.full_text = dataframe.full_text\n",
    "\t\tself.targets = self.data.scores\n",
    "\t\tself.max_len = max_len\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.full_text)\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tfull_text = str(self.full_text[index])\n",
    "\t\tfull_text = \" \".join(full_text.split())\n",
    "\n",
    "\t\tinputs = self.tokenizer.encode_plus(\n",
    "\t\t\tfull_text,\n",
    "\t\t\tNone,\n",
    "\t\t\tadd_special_tokens=True,\n",
    "\t\t\tmax_length=self.max_len,\n",
    "\t\t\tpadding='max_length',\n",
    "\t\t\ttruncation=True,\n",
    "\t\t\treturn_token_type_ids=True\n",
    "\t\t)\n",
    "\n",
    "\t\tids = inputs['input_ids']\n",
    "\t\tmask = inputs['attention_mask']\n",
    "\t\ttoken_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'ids': torch.LongTensor(ids),\n",
    "\t\t\t'mask': torch.LongTensor(mask),\n",
    "\t\t\t'token_type_ids': torch.LongTensor(token_type_ids),\n",
    "\t\t\t'targets': torch.LongTensor(self.targets[index])\n",
    "\t\t}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### HYPERPARAMETERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (3911, 3)\n",
      "TRAIN Dataset: (3129, 3)\n",
      "TEST Dataset: (782, 3)\n"
     ]
    }
   ],
   "source": [
    "# creating the dataset and the dataloader\n",
    "train_size = 0.8\n",
    "\n",
    "print(f\"FULL Dataset: {df.shape}\")\n",
    "\n",
    "train_ds = df.sample(frac=train_size, random_state=200)\n",
    "test_ds = df.drop(train_ds.index).reset_index(drop=True)\n",
    "train_ds = train_ds.reset_index(drop=True)\n",
    "\n",
    "print(f\"TRAIN Dataset: {train_ds.shape}\")\n",
    "print(f\"TEST Dataset: {test_ds.shape}\")\n",
    "\n",
    "train_set = CustomDataset(train_ds, tokenizer, MAX_LEN)\n",
    "test_set = CustomDataset(test_ds, tokenizer, MAX_LEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "\t\t\t\t'shuffle': True,\n",
    "\t\t\t\t'num_workers': 0\n",
    "\t\t\t\t}\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "\t\t\t\t'shuffle': True,\n",
    "\t\t\t\t'num_workers': 0\n",
    "\t\t\t\t}\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Classifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.3, inplace=False)\n",
       "  (out): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "class BERT_Classifier(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(BERT_Classifier, self).__init__()\n",
    "\t\tself.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\t\tself.drop = nn.Dropout(0.0)\n",
    "\t\tself.out = nn.Linear(768, 6)\n",
    "\n",
    "\tdef forward (self, ids, mask, token_type_ids):\n",
    "\t\t_, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "\t\toutput_2 = self.drop(pooled_output)\n",
    "\t\toutput = self.out(output_2)\n",
    "\t\treturn output\n",
    "\t\n",
    "model = BERT_Classifier()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the Model work?\n",
    "\n",
    "- We are using the BERT model. We then added a `Dropout` and `Linear Layer` as well. We add these layers to ensure the model is able to regularize and classify the data better.\n",
    "\n",
    "- In the forward loop, there are 2 outputs from the `BERT` model layer. \n",
    "\n",
    "- The output of this, `pooled_output` is passed through the `Dropout` layer and then the `Linear` layer.\n",
    "\n",
    "- We set the number of dimesnions in the `Linear` layer to be equal to the number of classes we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "\treturn nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\tmodel.train()\n",
    "\tfor idx, data in enumerate(train_loader, 0):\n",
    "\t\tids = data['ids'].to(device, dtype=torch.long)\n",
    "\t\tmask = data['mask'].to(device, dtype=torch.long)\n",
    "\t\ttoken_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "\t\ttargets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(ids, mask, token_type_ids)\n",
    "\t\tloss = loss_fn(outputs, targets)\n",
    "\t\tif idx % 100 == 0:\n",
    "\t\t\tprint(f\"Batch: {idx} | Loss: {loss.item()}\")\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\n",
    "\tprint(f\"EPOCH: {epoch} | LOSS: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0 | Loss: 0.38547179102897644\n",
      "Batch: 100 | Loss: -9.934698104858398\n",
      "Batch: 200 | Loss: -13.504341125488281\n",
      "Batch: 300 | Loss: -19.44586181640625\n",
      "EPOCH: 0 | LOSS: -30.354496002197266\n",
      "Batch: 0 | Loss: -19.200740814208984\n",
      "Batch: 100 | Loss: -24.988859176635742\n",
      "Batch: 200 | Loss: -30.479351043701172\n",
      "Batch: 300 | Loss: -38.318939208984375\n",
      "EPOCH: 1 | LOSS: -46.97802734375\n",
      "Batch: 0 | Loss: -30.341270446777344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \ttrain(epoch)\n",
      "\u001b[1;32m/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(epoch):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \tmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \t\tids \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \t\tmask \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m full_text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_text[index])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m full_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(full_text\u001b[39m.\u001b[39msplit())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mencode_plus(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \tfull_text,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \t\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \tadd_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \tmax_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_len,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \tpadding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \ttruncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \treturn_token_type_ids\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m ids \u001b[39m=\u001b[39m inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vineetraju/Documents/code/old/programming/bu/cs505/final_project/data_exploration.ipynb#X45sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m mask \u001b[39m=\u001b[39m inputs[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2781\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2771\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2772\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2773\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2774\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2778\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2779\u001b[0m )\n\u001b[0;32m-> 2781\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[1;32m   2782\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   2783\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2784\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2785\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2786\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2787\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2788\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2789\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2790\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2791\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2792\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2793\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2794\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2795\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2796\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2797\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2798\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2799\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2800\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils.py:656\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    648\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    649\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    650\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m     )\n\u001b[0;32m--> 656\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    657\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_model(\n\u001b[1;32m    660\u001b[0m     first_ids,\n\u001b[1;32m    661\u001b[0m     pair_ids\u001b[39m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    676\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils.py:623\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[1;32m    622\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 623\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    624\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    625\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils.py:554\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         tokenized_text\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         tokenized_text\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenize(token))\n\u001b[1;32m    555\u001b[0m \u001b[39m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:244\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    242\u001b[0m split_tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_basic_tokenize:\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_tokenizer\u001b[39m.\u001b[39;49mtokenize(\n\u001b[1;32m    245\u001b[0m         text, never_split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_special_tokens \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m split_special_tokens \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         \u001b[39m# If the token is part of the never_split set\u001b[39;00m\n\u001b[1;32m    248\u001b[0m         \u001b[39mif\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbasic_tokenizer\u001b[39m.\u001b[39mnever_split:\n\u001b[1;32m    249\u001b[0m             split_tokens\u001b[39m.\u001b[39mappend(token)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:444\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrip_accents:\n\u001b[1;32m    443\u001b[0m             token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_strip_accents(token)\n\u001b[0;32m--> 444\u001b[0m     split_tokens\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_split_on_punc(token, never_split))\n\u001b[1;32m    446\u001b[0m output_tokens \u001b[39m=\u001b[39m whitespace_tokenize(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(split_tokens))\n\u001b[1;32m    447\u001b[0m \u001b[39mreturn\u001b[39;00m output_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:470\u001b[0m, in \u001b[0;36mBasicTokenizer._run_split_on_punc\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(chars):\n\u001b[1;32m    469\u001b[0m     char \u001b[39m=\u001b[39m chars[i]\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mif\u001b[39;00m _is_punctuation(char):\n\u001b[1;32m    471\u001b[0m         output\u001b[39m.\u001b[39mappend([char])\n\u001b[1;32m    472\u001b[0m         start_new_word \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/transformers/tokenization_utils.py:299\u001b[0m, in \u001b[0;36m_is_punctuation\u001b[0;34m(char)\u001b[0m\n\u001b[1;32m    294\u001b[0m cp \u001b[39m=\u001b[39m \u001b[39mord\u001b[39m(char)\n\u001b[1;32m    295\u001b[0m \u001b[39m# We treat all non-letter/number ASCII as punctuation.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m# Punctuation class but we treat them as punctuation anyways, for\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39m# consistency.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m \u001b[39mif\u001b[39;00m (cp \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m33\u001b[39m \u001b[39mand\u001b[39;00m cp \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m47\u001b[39m) \u001b[39mor\u001b[39;00m (cp \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m58\u001b[39m \u001b[39mand\u001b[39;00m cp \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m64\u001b[39m) \u001b[39mor\u001b[39;00m (cp \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m91\u001b[39m \u001b[39mand\u001b[39;00m cp \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m96\u001b[39m) \u001b[39mor\u001b[39;00m (cp \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m123\u001b[39m \u001b[39mand\u001b[39;00m cp \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m126\u001b[39m):\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    301\u001b[0m cat \u001b[39m=\u001b[39m unicodedata\u001b[39m.\u001b[39mcategory(char)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\ttrain(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "\tmodel.eval()\n",
    "\tfin_targets = []\n",
    "\tfin_outputs = []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor _, data in enumerate(test_loader, 0):\n",
    "\t\t\tids = data['ids'].to(device, dtype=torch.long)\n",
    "\t\t\tmask = data['mask'].to(device, dtype=torch.long)\n",
    "\t\t\ttoken_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "\t\t\ttargets = data['targets'].to(device, dtype=torch.long)\n",
    "\t\t\toutputs = model(ids, mask, token_type_ids)\n",
    "\t\t\tfin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "\t\t\tfin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\treturn fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(outputs, targets):\n",
    "\tprint(outputs[0], targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999994039535522, 0.9999992847442627, 0.9999995231628418, 0.9999997615814209, 0.9999997615814209, 0.9999986886978149] [5, 3, 3, 3, 2, 4]\n",
      "EPOCH: 0 | ACCURACY: None\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\toutputs, targets = validation(epoch=epoch)\n",
    "\taccuracy = calculate_accuracy(outputs, targets)\n",
    "\tprint(f\"EPOCH: {epoch} | ACCURACY: {accuracy}\")\n",
    "\tbreak\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
