{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load essays and tag every word in the essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing essays: 100%|██████████| 15594/15594 [00:03<00:00, 4661.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading all essays/texts\n",
    "\n",
    "essay_dir = '../data/feedback-prize-2021/train'\n",
    "\n",
    "essays_data = []\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "for filename in tqdm(os.listdir(essay_dir), desc=\"Processing essays\"):\n",
    "    if filename.endswith('.txt'):\n",
    "        essay_id = filename[:-4]\n",
    "        file_path = os.path.join(essay_dir, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            essay_text = file.read()\n",
    "            essay_text_no_punct = remove_punctuation(essay_text)\n",
    "            essays_data.append((essay_id, essay_text_no_punct.split()))\n",
    "\n",
    "essays_df = pd.DataFrame(essays_data, columns=['id', 'essay_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dear', 'state', 'senator', 'Many', 'people', 'believe', 'that', 'the', 'Electoral', 'College', 'should', 'be', 'abolished', 'while', 'others', 'believe', 'that', 'the', 'Electoral', 'College', 'should', 'stay', 'as', 'it', 'is', 'However', 'what', 'most', 'people', 'who', 'want', 'to', 'keep', 'the', 'electoral', 'college', 'do', 'not', 'know', 'is', 'that', 'when', 'you', 'vote', 'for', 'a', 'presidential', 'candidate', 'you', 'are', 'actually', 'voting', 'for', 'a', 'slate', 'of', 'electors', 'who', 'in', 'turn', 'elect', 'the', 'president', 'Which', 'means', 'that', 'the', 'people', 'do', 'not', 'get', 'a', 'direct', 'vote', 'towards', 'the', 'president', 'Therefore', 'it', 'can', 'cause', 'disinterest', 'in', 'people', 'who', 'are', 'eligible', 'to', 'vote', 'That', 'is', 'why', 'I', 'argue', 'in', 'favor', 'of', 'changing', 'to', 'election', 'by', 'popular', 'vote', 'for', 'the', 'president', 'of', 'the', 'United', 'States', 'The', 'first', 'reason', 'as', 'to', 'why', 'I', 'favor', 'in', 'abolishing', 'the', 'Electoral', 'college', 'is', 'because', 'you', 'can', 'not', 'always', 'trust', 'the', 'electors', 'As', 'shown', 'back', 'in', '1960', 'segregationists', 'in', 'the', 'Louisiana', 'legislature', 'nearly', 'succeeded', 'in', 'replacing', 'Democratic', 'electors', 'with', 'new', 'electors', 'who', 'would', 'oppose', 'John', 'F', 'Kennedy', 'so', 'that', 'a', 'popular', 'vote', 'for', 'Kennedy', 'would', 'not', 'have', 'actually', 'gone', 'to', 'Kennedy', 'Also', 'due', 'to', 'the', 'winnertakeall', 'system', 'candidates', 'do', 'not', 'spend', 'time', 'in', 'states', 'they', 'know', 'they', 'have', 'no', 'chance', 'in', 'winning', 'it', 'is', 'obvious', 'that', 'they', 'just', 'want', 'to', 'win', 'and', 'you', 'can', 'not', 'trust', 'those', 'candidates', 'especially', 'the', 'people', 'who', 'promise', 'to', 'do', 'things', 'they', 'know', 'they', 'can', 'not', 'fulfill', 'The', 'electors', 'that', 'the', 'people', 'vote', 'for', 'do', 'not', 'want', 'to', 'help', 'their', 'state', 'they', 'do', 'not', 'even', 'care', 'for', 'the', 'needs', 'of', 'the', 'people', 'they', 'are', 'just', 'there', 'for', 'the', 'money', 'Another', 'reason', 'as', 'to', 'why', 'you', 'can', 'not', 'trust', 'the', 'electors', 'is', 'because', 'it', 'is', 'known', 'that', 'the', 'electors', 'can', 'vote', 'for', 'whomever', 'they', 'choose', 'and', 'forget', 'about', 'the', 'peoples', 'needs', 'One', 'of', 'the', 'main', 'reasons', 'as', 'to', 'why', 'this', 'causes', 'disintrest', 'in', 'potential', 'voters', 'If', 'the', 'people', 'vote', 'directly', 'for', 'the', 'president', 'they', 'have', 'a', 'better', 'chance', 'in', 'speaking', 'up', 'and', 'fighting', 'for', 'what', 'they', 'want', 'therefore', 'trusting', 'Those', 'are', 'some', 'of', 'the', 'rights', 'that', 'are', 'taken', 'away', 'by', 'the', 'electoral', 'college', 'and', 'people', 'do', 'not', 'even', 'realize', 'it', 'Another', 'reason', 'as', 'to', 'why', 'I', 'believe', 'the', 'electoral', 'college', 'should', 'be', 'abolished', 'is', 'because', 'the', 'electoral', 'college', 'is', 'unfair', 'to', 'voters', 'Over', '60', 'percent', 'of', 'voters', 'would', 'prefer', 'a', 'direct', 'election', 'to', 'the', 'kind', 'we', 'have', 'now', 'That', 'is', 'more', 'than', 'half', 'of', 'the', 'people', 'If', 'the', 'government', 'really', 'cared', 'for', 'what', 'the', 'people', 'want', 'the', 'electoral', 'college', 'would', 'have', 'been', 'abolished', 'by', 'now', 'Studies', 'have', 'shown', 'that', 'only', 'half', 'of', 'the', 'people', 'living', 'in', 'the', 'US', 'have', 'voted', 'in', 'the', 'pasts', 'elections', 'If', 'you', 'really', 'want', 'the', 'number', 'of', 'voters', 'to', 'increase', 'and', 'for', 'citizens', 'of', 'the', 'US', 'to', 'express', 'their', 'political', 'preferences', 'you', 'should', 'actually', 'listen', 'to', 'them', 'and', 'abolish', 'the', 'electoral', 'college', 'Lastly', 'the', 'electoral', 'college', 'prevents', 'voters', 'from', 'controling', 'who', 'they', 'vote', 'for', 'Many', 'voters', 'now', 'in', 'days', 'believe', 'that', 'when', 'they', 'vote', 'their', 'one', 'vote', 'decides', 'the', 'election', 'but', 'they', 'are', 'wrong', 'If', 'they', 'abolish', 'the', 'electoral', 'college', 'the', 'voters', 'would', 'have', 'a', 'better', 'chance', 'in', 'having', 'who', 'they', 'want', 'for', 'president', 'The', 'people', 'who', 'vote', 'in', 'presidential', 'elections', 'are', 'people', 'who', 'want', 'to', 'express', 'a', 'political', 'preference', 'well', 'have', 'more', 'citizens', 'voting', 'if', 'the', 'electoral', 'college', 'is', 'abolished', 'How', 'do', 'you', 'expect', 'for', 'US', 'citizens', 'to', 'vote', 'and', 'express', 'themselves', 'if', 'they', 'are', 'not', 'heard']\n"
     ]
    }
   ],
   "source": [
    "text = (essays_df[essays_df[\"id\"] == '0A0AA9C21C5D'][\"essay_text\"]).iloc[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>essay_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>[I, do, agree, that, some, students, would, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>[Should, students, design, a, summer, project,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>[Dear, State, Senator, In, the, ruels, of, vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>[People, sometimes, have, a, different, opinio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>[Dear, senator, As, you, know, the, Electoral,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>1C899F124FEB</td>\n",
       "      <td>[While, some, students, may, think, its, a, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>4453444AF383</td>\n",
       "      <td>[There, has, been, a, strong, arguement, going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>EF0D75BF48DA</td>\n",
       "      <td>[I, favor, in, to, changing, election, by, pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>8FFDA5B9D359</td>\n",
       "      <td>[Do, you, think, students, would, benefit, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>ACAB1FCA0A30</td>\n",
       "      <td>[I, would, like, to, change, the, election, fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                         essay_text\n",
       "0      3321A3E87AD3  [I, do, agree, that, some, students, would, be...\n",
       "1      DFEAEC512BAB  [Should, students, design, a, summer, project,...\n",
       "2      2E4AFCD3987F  [Dear, State, Senator, In, the, ruels, of, vot...\n",
       "3      EB6C2AF20BFE  [People, sometimes, have, a, different, opinio...\n",
       "4      A91A08E523D5  [Dear, senator, As, you, know, the, Electoral,...\n",
       "...             ...                                                ...\n",
       "15589  1C899F124FEB  [While, some, students, may, think, its, a, be...\n",
       "15590  4453444AF383  [There, has, been, a, strong, arguement, going...\n",
       "15591  EF0D75BF48DA  [I, favor, in, to, changing, election, by, pop...\n",
       "15592  8FFDA5B9D359  [Do, you, think, students, would, benefit, fro...\n",
       "15593  ACAB1FCA0A30  [I, would, like, to, change, the, election, fo...\n",
       "\n",
       "[15594 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                         essay_text  \\\n",
      "0  0000D23A521A  [Some, people, belive, that, the, so, called, ...   \n",
      "1  00066EA9880D  [Driverless, cars, are, exaclty, what, you, wo...   \n",
      "2  000E6DE9E817  [I, am, arguing, against, the, policy, change,...   \n",
      "3  001552828BD0  [Would, you, be, able, to, give, your, car, up...   \n",
      "4  0016926B079C  [I, think, that, students, would, benefit, fro...   \n",
      "\n",
      "                                                tags  \n",
      "0  [Position, Position, Position, Position, Posit...  \n",
      "1  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
      "2  [Position, Position, Position, Position, Posit...  \n",
      "3  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
      "4  [Position, Position, Position, Position, Posit...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('../data/feedback-prize-2021/train.csv')\n",
    "\n",
    "\n",
    "# Sort the DataFrame by 'id' and 'discourse_start' to ensure proper order\n",
    "df = df.sort_values(by=['id', 'discourse_start'])\n",
    "\n",
    "# Initialize a dictionary to hold the essays\n",
    "essays = {}\n",
    "\n",
    "# Process each essay\n",
    "for _, row in df.iterrows():\n",
    "    essay_id = row['id']\n",
    "    discourse_words = row['discourse_text'].split()\n",
    "    discourse_tags = [row['discourse_type']] * len(discourse_words)\n",
    "\n",
    "    if essay_id not in essays:\n",
    "        essays[essay_id] = {'words': [], 'tags': []}\n",
    "\n",
    "    essays[essay_id]['words'].extend(discourse_words)\n",
    "    essays[essay_id]['tags'].extend(discourse_tags)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "essays_df = pd.DataFrame([(essay_id, data['words'], data['tags']) for essay_id, data in essays.items()],\n",
    "                         columns=['id', 'essay_text', 'tags'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(essays_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize essays and align tags correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df.to_pickle('../data/preprocess_step1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches found: 0\n"
     ]
    }
   ],
   "source": [
    "mismatch_count = 0\n",
    "\n",
    "for index, row in essays_df.iterrows():\n",
    "    # Assuming 'essay_text' is an array of words and 'tags' is an array of tags\n",
    "    if len(row['tags']) != len(row['essay_text']):\n",
    "        mismatch_count += 1\n",
    "        # Optionally, print details about the mismatches\n",
    "        print(f\"Mismatch in row {index}: {len(row['tags'])} tags, {len(row['essay_text'])} words\")\n",
    "\n",
    "print(f\"Total mismatches found: {mismatch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches found: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "\n",
    "essays_df = pd.read_pickle('../data/preprocess_step1.pkl')\n",
    "\n",
    "mismatch_count = 0\n",
    "\n",
    "for index, row in essays_df.iterrows():\n",
    "    # Assuming 'essay_text' is an array of words and 'tags' is an array of tags\n",
    "    if len(row['tags']) != len(row['essay_text']):\n",
    "        mismatch_count += 1\n",
    "        # Optionally, print details about the mismatches\n",
    "        print(f\"Mismatch in row {index}: {len(row['tags'])} tags, {len(row['essay_text'])} words\")\n",
    "\n",
    "print(f\"Total mismatches found: {mismatch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing and Aligning: 100%|██████████| 15594/15594 [00:17<00:00, 884.20it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "tokenized_data = []\n",
    "\n",
    "def align_tags_with_tokens(tags, words, tokenized_words):\n",
    "    aligned_tags = []\n",
    "    word_index = 0 \n",
    "\n",
    "    for token in tokenized_words:\n",
    "        if word_index >= len(tags):  \n",
    "            break \n",
    "\n",
    "        if token.startswith(\"##\"):\n",
    "            aligned_tags.append(tags[word_index - 1])\n",
    "        else:\n",
    "            aligned_tags.append(tags[word_index])\n",
    "            word_index += 1\n",
    "\n",
    "    return aligned_tags\n",
    "\n",
    "for _, row in tqdm(essays_df.iterrows(), total=essays_df.shape[0], desc=\"Tokenizing and Aligning\"):\n",
    "    tokens = tokenizer.tokenize(' '.join(row['essay_text']))\n",
    "\n",
    "    aligned_tags = align_tags_with_tokens(row['tags'], row['essay_text'], tokens)\n",
    "\n",
    "    tokenized_data.append({\n",
    "        'id': row['id'],\n",
    "        'tokens': tokens,\n",
    "        'aligned_tags': aligned_tags\n",
    "    })\n",
    "\n",
    "tokenized_df = pd.DataFrame(tokenized_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>aligned_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>[Some, Ġpeople, Ġbel, ive, Ġthat, Ġthe, Ġso, Ġ...</td>\n",
       "      <td>[Position, Position, Position, Position, Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>[Driver, less, Ġcars, Ġare, Ġex, acl, ty, Ġwha...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>[I, Ġam, Ġarguing, Ġagainst, Ġthe, Ġpolicy, Ġc...</td>\n",
       "      <td>[Position, Position, Position, Position, Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>[Would, Ġyou, Ġbe, Ġable, Ġto, Ġgive, Ġyour, Ġ...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>[I, Ġthink, Ġthat, Ġstudents, Ġwould, Ġbenefit...</td>\n",
       "      <td>[Position, Position, Position, Position, Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>[Every, Ġstudent, Ġlooks, Ġforward, Ġto, Ġsumm...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>FFF1ED4F8544</td>\n",
       "      <td>[Many, Ġcitizens, Ġargue, Ġthat, Ġthe, ĠElecto...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>FFF868E06176</td>\n",
       "      <td>[Every, Ġsummer, Ġbreak, ,, Ġstudents, Ġare, Ġ...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>FFFD0AF13501</td>\n",
       "      <td>[they, Ġget, Ġto, Ġsee, Ġtons, Ġof, Ġawesome, ...</td>\n",
       "      <td>[Claim, Claim, Claim, Claim, Claim, Claim, Cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>[Ven, us, Ġis, Ġa, Ġplanet, Ġwhat, Ġbelong, Ġt...</td>\n",
       "      <td>[Evidence, Evidence, Evidence, Evidence, Evide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                             tokens  \\\n",
       "0      0000D23A521A  [Some, Ġpeople, Ġbel, ive, Ġthat, Ġthe, Ġso, Ġ...   \n",
       "1      00066EA9880D  [Driver, less, Ġcars, Ġare, Ġex, acl, ty, Ġwha...   \n",
       "2      000E6DE9E817  [I, Ġam, Ġarguing, Ġagainst, Ġthe, Ġpolicy, Ġc...   \n",
       "3      001552828BD0  [Would, Ġyou, Ġbe, Ġable, Ġto, Ġgive, Ġyour, Ġ...   \n",
       "4      0016926B079C  [I, Ġthink, Ġthat, Ġstudents, Ġwould, Ġbenefit...   \n",
       "...             ...                                                ...   \n",
       "15589  FFF1442D6698  [Every, Ġstudent, Ġlooks, Ġforward, Ġto, Ġsumm...   \n",
       "15590  FFF1ED4F8544  [Many, Ġcitizens, Ġargue, Ġthat, Ġthe, ĠElecto...   \n",
       "15591  FFF868E06176  [Every, Ġsummer, Ġbreak, ,, Ġstudents, Ġare, Ġ...   \n",
       "15592  FFFD0AF13501  [they, Ġget, Ġto, Ġsee, Ġtons, Ġof, Ġawesome, ...   \n",
       "15593  FFFF80B8CC2F  [Ven, us, Ġis, Ġa, Ġplanet, Ġwhat, Ġbelong, Ġt...   \n",
       "\n",
       "                                            aligned_tags  \n",
       "0      [Position, Position, Position, Position, Posit...  \n",
       "1      [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "2      [Position, Position, Position, Position, Posit...  \n",
       "3      [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "4      [Position, Position, Position, Position, Posit...  \n",
       "...                                                  ...  \n",
       "15589  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "15590  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "15591  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "15592  [Claim, Claim, Claim, Claim, Claim, Claim, Cla...  \n",
       "15593  [Evidence, Evidence, Evidence, Evidence, Evide...  \n",
       "\n",
       "[15594 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df.to_pickle('../data/preprocess_step2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                             tokens  \\\n",
      "0  0000D23A521A  [Some, Ġpeople, Ġbel, ive, Ġthat, Ġthe, Ġso, Ġ...   \n",
      "\n",
      "                                        aligned_tags  \n",
      "0  [Position, Position, Position, Position, Posit...  \n"
     ]
    }
   ],
   "source": [
    "print(tokenized_df[tokenized_df['id']=='0000D23A521A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
