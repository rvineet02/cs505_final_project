{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load essays and tag every word in the essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing essays: 100%|██████████| 15594/15594 [00:03<00:00, 4661.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading all essays/texts\n",
    "\n",
    "essay_dir = '../data/feedback-prize-2021/train'\n",
    "\n",
    "essays_data = []\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "for filename in tqdm(os.listdir(essay_dir), desc=\"Processing essays\"):\n",
    "    if filename.endswith('.txt'):\n",
    "        essay_id = filename[:-4]\n",
    "        file_path = os.path.join(essay_dir, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            essay_text = file.read()\n",
    "            essay_text_no_punct = remove_punctuation(essay_text)\n",
    "            essays_data.append((essay_id, essay_text_no_punct.split()))\n",
    "\n",
    "essays_df = pd.DataFrame(essays_data, columns=['id', 'essay_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dear', 'state', 'senator', 'Many', 'people', 'believe', 'that', 'the', 'Electoral', 'College', 'should', 'be', 'abolished', 'while', 'others', 'believe', 'that', 'the', 'Electoral', 'College', 'should', 'stay', 'as', 'it', 'is', 'However', 'what', 'most', 'people', 'who', 'want', 'to', 'keep', 'the', 'electoral', 'college', 'do', 'not', 'know', 'is', 'that', 'when', 'you', 'vote', 'for', 'a', 'presidential', 'candidate', 'you', 'are', 'actually', 'voting', 'for', 'a', 'slate', 'of', 'electors', 'who', 'in', 'turn', 'elect', 'the', 'president', 'Which', 'means', 'that', 'the', 'people', 'do', 'not', 'get', 'a', 'direct', 'vote', 'towards', 'the', 'president', 'Therefore', 'it', 'can', 'cause', 'disinterest', 'in', 'people', 'who', 'are', 'eligible', 'to', 'vote', 'That', 'is', 'why', 'I', 'argue', 'in', 'favor', 'of', 'changing', 'to', 'election', 'by', 'popular', 'vote', 'for', 'the', 'president', 'of', 'the', 'United', 'States', 'The', 'first', 'reason', 'as', 'to', 'why', 'I', 'favor', 'in', 'abolishing', 'the', 'Electoral', 'college', 'is', 'because', 'you', 'can', 'not', 'always', 'trust', 'the', 'electors', 'As', 'shown', 'back', 'in', '1960', 'segregationists', 'in', 'the', 'Louisiana', 'legislature', 'nearly', 'succeeded', 'in', 'replacing', 'Democratic', 'electors', 'with', 'new', 'electors', 'who', 'would', 'oppose', 'John', 'F', 'Kennedy', 'so', 'that', 'a', 'popular', 'vote', 'for', 'Kennedy', 'would', 'not', 'have', 'actually', 'gone', 'to', 'Kennedy', 'Also', 'due', 'to', 'the', 'winnertakeall', 'system', 'candidates', 'do', 'not', 'spend', 'time', 'in', 'states', 'they', 'know', 'they', 'have', 'no', 'chance', 'in', 'winning', 'it', 'is', 'obvious', 'that', 'they', 'just', 'want', 'to', 'win', 'and', 'you', 'can', 'not', 'trust', 'those', 'candidates', 'especially', 'the', 'people', 'who', 'promise', 'to', 'do', 'things', 'they', 'know', 'they', 'can', 'not', 'fulfill', 'The', 'electors', 'that', 'the', 'people', 'vote', 'for', 'do', 'not', 'want', 'to', 'help', 'their', 'state', 'they', 'do', 'not', 'even', 'care', 'for', 'the', 'needs', 'of', 'the', 'people', 'they', 'are', 'just', 'there', 'for', 'the', 'money', 'Another', 'reason', 'as', 'to', 'why', 'you', 'can', 'not', 'trust', 'the', 'electors', 'is', 'because', 'it', 'is', 'known', 'that', 'the', 'electors', 'can', 'vote', 'for', 'whomever', 'they', 'choose', 'and', 'forget', 'about', 'the', 'peoples', 'needs', 'One', 'of', 'the', 'main', 'reasons', 'as', 'to', 'why', 'this', 'causes', 'disintrest', 'in', 'potential', 'voters', 'If', 'the', 'people', 'vote', 'directly', 'for', 'the', 'president', 'they', 'have', 'a', 'better', 'chance', 'in', 'speaking', 'up', 'and', 'fighting', 'for', 'what', 'they', 'want', 'therefore', 'trusting', 'Those', 'are', 'some', 'of', 'the', 'rights', 'that', 'are', 'taken', 'away', 'by', 'the', 'electoral', 'college', 'and', 'people', 'do', 'not', 'even', 'realize', 'it', 'Another', 'reason', 'as', 'to', 'why', 'I', 'believe', 'the', 'electoral', 'college', 'should', 'be', 'abolished', 'is', 'because', 'the', 'electoral', 'college', 'is', 'unfair', 'to', 'voters', 'Over', '60', 'percent', 'of', 'voters', 'would', 'prefer', 'a', 'direct', 'election', 'to', 'the', 'kind', 'we', 'have', 'now', 'That', 'is', 'more', 'than', 'half', 'of', 'the', 'people', 'If', 'the', 'government', 'really', 'cared', 'for', 'what', 'the', 'people', 'want', 'the', 'electoral', 'college', 'would', 'have', 'been', 'abolished', 'by', 'now', 'Studies', 'have', 'shown', 'that', 'only', 'half', 'of', 'the', 'people', 'living', 'in', 'the', 'US', 'have', 'voted', 'in', 'the', 'pasts', 'elections', 'If', 'you', 'really', 'want', 'the', 'number', 'of', 'voters', 'to', 'increase', 'and', 'for', 'citizens', 'of', 'the', 'US', 'to', 'express', 'their', 'political', 'preferences', 'you', 'should', 'actually', 'listen', 'to', 'them', 'and', 'abolish', 'the', 'electoral', 'college', 'Lastly', 'the', 'electoral', 'college', 'prevents', 'voters', 'from', 'controling', 'who', 'they', 'vote', 'for', 'Many', 'voters', 'now', 'in', 'days', 'believe', 'that', 'when', 'they', 'vote', 'their', 'one', 'vote', 'decides', 'the', 'election', 'but', 'they', 'are', 'wrong', 'If', 'they', 'abolish', 'the', 'electoral', 'college', 'the', 'voters', 'would', 'have', 'a', 'better', 'chance', 'in', 'having', 'who', 'they', 'want', 'for', 'president', 'The', 'people', 'who', 'vote', 'in', 'presidential', 'elections', 'are', 'people', 'who', 'want', 'to', 'express', 'a', 'political', 'preference', 'well', 'have', 'more', 'citizens', 'voting', 'if', 'the', 'electoral', 'college', 'is', 'abolished', 'How', 'do', 'you', 'expect', 'for', 'US', 'citizens', 'to', 'vote', 'and', 'express', 'themselves', 'if', 'they', 'are', 'not', 'heard']\n"
     ]
    }
   ],
   "source": [
    "text = (essays_df[essays_df[\"id\"] == '0A0AA9C21C5D'][\"essay_text\"]).iloc[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>essay_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>[I, do, agree, that, some, students, would, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>[Should, students, design, a, summer, project,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>[Dear, State, Senator, In, the, ruels, of, vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>[People, sometimes, have, a, different, opinio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>[Dear, senator, As, you, know, the, Electoral,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>1C899F124FEB</td>\n",
       "      <td>[While, some, students, may, think, its, a, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>4453444AF383</td>\n",
       "      <td>[There, has, been, a, strong, arguement, going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>EF0D75BF48DA</td>\n",
       "      <td>[I, favor, in, to, changing, election, by, pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>8FFDA5B9D359</td>\n",
       "      <td>[Do, you, think, students, would, benefit, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>ACAB1FCA0A30</td>\n",
       "      <td>[I, would, like, to, change, the, election, fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                         essay_text\n",
       "0      3321A3E87AD3  [I, do, agree, that, some, students, would, be...\n",
       "1      DFEAEC512BAB  [Should, students, design, a, summer, project,...\n",
       "2      2E4AFCD3987F  [Dear, State, Senator, In, the, ruels, of, vot...\n",
       "3      EB6C2AF20BFE  [People, sometimes, have, a, different, opinio...\n",
       "4      A91A08E523D5  [Dear, senator, As, you, know, the, Electoral,...\n",
       "...             ...                                                ...\n",
       "15589  1C899F124FEB  [While, some, students, may, think, its, a, be...\n",
       "15590  4453444AF383  [There, has, been, a, strong, arguement, going...\n",
       "15591  EF0D75BF48DA  [I, favor, in, to, changing, election, by, pop...\n",
       "15592  8FFDA5B9D359  [Do, you, think, students, would, benefit, fro...\n",
       "15593  ACAB1FCA0A30  [I, would, like, to, change, the, election, fo...\n",
       "\n",
       "[15594 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/feedback-prize-2021/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging: 100%|██████████| 15594/15594 [01:11<00:00, 217.91it/s]\n"
     ]
    }
   ],
   "source": [
    "essays_df['tags'] = None\n",
    "\n",
    "\n",
    "def create_tag_array(text):\n",
    "    return ['O'] * len(text)\n",
    "\n",
    "def update_tags(tags, predictionstring, discourse_type, len_essay):\n",
    "    indices = list(map(int, predictionstring.split()))\n",
    "    for index in indices:\n",
    "        if index >= (len_essay):\n",
    "            return tags\n",
    "        tags[index] = discourse_type\n",
    "    return tags\n",
    "\n",
    "for index, row in tqdm(essays_df.iterrows(), total=essays_df.shape[0], desc=\"Tagging\"):\n",
    "    tags = create_tag_array(row['essay_text'])\n",
    "\n",
    "    essay_annotations = train[train['id'] == row['id']]\n",
    "\n",
    "    for _, annotation_row in essay_annotations.iterrows():\n",
    "        tags = update_tags(tags, annotation_row['predictionstring'], annotation_row['discourse_type'], len(row['essay_text']))\n",
    "\n",
    "    if len(tags) != len(row['essay_text']):\n",
    "        print(f\"Length mismatch: {len(tags)} tags, {len(row['essay_text'])} words\")\n",
    "    \n",
    "    essays_df.at[index, 'tags'] = tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "print(len(essays_df.iloc[0][\"essay_text\"]))\n",
    "print(len(essays_df.iloc[0][\"tags\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize essays and align tags correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df.to_pickle('../data/preprocess_step1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches found: 0\n"
     ]
    }
   ],
   "source": [
    "mismatch_count = 0\n",
    "\n",
    "for index, row in essays_df.iterrows():\n",
    "    # Assuming 'essay_text' is an array of words and 'tags' is an array of tags\n",
    "    if len(row['tags']) != len(row['essay_text']):\n",
    "        mismatch_count += 1\n",
    "        # Optionally, print details about the mismatches\n",
    "        print(f\"Mismatch in row {index}: {len(row['tags'])} tags, {len(row['essay_text'])} words\")\n",
    "\n",
    "print(f\"Total mismatches found: {mismatch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches found: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "\n",
    "essays_df = pd.read_pickle('../data/preprocess_step1.pkl')\n",
    "\n",
    "mismatch_count = 0\n",
    "\n",
    "for index, row in essays_df.iterrows():\n",
    "    # Assuming 'essay_text' is an array of words and 'tags' is an array of tags\n",
    "    if len(row['tags']) != len(row['essay_text']):\n",
    "        mismatch_count += 1\n",
    "        # Optionally, print details about the mismatches\n",
    "        print(f\"Mismatch in row {index}: {len(row['tags'])} tags, {len(row['essay_text'])} words\")\n",
    "\n",
    "print(f\"Total mismatches found: {mismatch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing and Aligning: 100%|██████████| 15594/15594 [00:17<00:00, 884.04it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "tokenized_data = []\n",
    "\n",
    "def align_tags_with_tokens(tags, words, tokenized_words):\n",
    "    aligned_tags = []\n",
    "    word_index = 0 \n",
    "\n",
    "    for token in tokenized_words:\n",
    "        if word_index >= len(tags):  \n",
    "            break \n",
    "\n",
    "        if token.startswith(\"##\"):\n",
    "            aligned_tags.append(tags[word_index - 1])\n",
    "        else:\n",
    "            aligned_tags.append(tags[word_index])\n",
    "            word_index += 1\n",
    "\n",
    "    return aligned_tags\n",
    "\n",
    "    return aligned_tags\n",
    "\n",
    "for _, row in tqdm(essays_df.iterrows(), total=essays_df.shape[0], desc=\"Tokenizing and Aligning\"):\n",
    "    tokens = tokenizer.tokenize(' '.join(row['essay_text']))\n",
    "\n",
    "    aligned_tags = align_tags_with_tokens(row['tags'], row['essay_text'], tokens)\n",
    "\n",
    "    tokenized_data.append({\n",
    "        'id': row['id'],\n",
    "        'tokens': tokens,\n",
    "        'aligned_tags': aligned_tags\n",
    "    })\n",
    "\n",
    "tokenized_df = pd.DataFrame(tokenized_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>aligned_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>[I, Ġdo, Ġagree, Ġthat, Ġsome, Ġstudents, Ġwou...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>[Should, Ġstudents, Ġdesign, Ġa, Ġsummer, Ġpro...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, Position, Position, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>[Dear, ĠState, ĠSenator, ĠIn, Ġthe, Ġru, els, ...</td>\n",
       "      <td>[O, O, O, O, Position, Position, Position, Pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>[People, Ġsometimes, Ġhave, Ġa, Ġdifferent, Ġo...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>[Dear, Ġsenator, ĠAs, Ġyou, Ġknow, Ġthe, ĠElec...</td>\n",
       "      <td>[O, O, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>1C899F124FEB</td>\n",
       "      <td>[While, Ġsome, Ġstudents, Ġmay, Ġthink, Ġits, ...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>4453444AF383</td>\n",
       "      <td>[There, Ġhas, Ġbeen, Ġa, Ġstrong, Ġarg, u, eme...</td>\n",
       "      <td>[Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>EF0D75BF48DA</td>\n",
       "      <td>[I, Ġfavor, Ġin, Ġto, Ġchanging, Ġelection, Ġb...</td>\n",
       "      <td>[Position, Position, Position, Position, Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>8FFDA5B9D359</td>\n",
       "      <td>[Do, Ġyou, Ġthink, Ġstudents, Ġwould, Ġbenefit...</td>\n",
       "      <td>[Position, Position, Position, Position, Posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>ACAB1FCA0A30</td>\n",
       "      <td>[I, Ġwould, Ġlike, Ġto, Ġchange, Ġthe, Ġelecti...</td>\n",
       "      <td>[Position, Position, Position, Position, Posit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                             tokens  \\\n",
       "0      3321A3E87AD3  [I, Ġdo, Ġagree, Ġthat, Ġsome, Ġstudents, Ġwou...   \n",
       "1      DFEAEC512BAB  [Should, Ġstudents, Ġdesign, Ġa, Ġsummer, Ġpro...   \n",
       "2      2E4AFCD3987F  [Dear, ĠState, ĠSenator, ĠIn, Ġthe, Ġru, els, ...   \n",
       "3      EB6C2AF20BFE  [People, Ġsometimes, Ġhave, Ġa, Ġdifferent, Ġo...   \n",
       "4      A91A08E523D5  [Dear, Ġsenator, ĠAs, Ġyou, Ġknow, Ġthe, ĠElec...   \n",
       "...             ...                                                ...   \n",
       "15589  1C899F124FEB  [While, Ġsome, Ġstudents, Ġmay, Ġthink, Ġits, ...   \n",
       "15590  4453444AF383  [There, Ġhas, Ġbeen, Ġa, Ġstrong, Ġarg, u, eme...   \n",
       "15591  EF0D75BF48DA  [I, Ġfavor, Ġin, Ġto, Ġchanging, Ġelection, Ġb...   \n",
       "15592  8FFDA5B9D359  [Do, Ġyou, Ġthink, Ġstudents, Ġwould, Ġbenefit...   \n",
       "15593  ACAB1FCA0A30  [I, Ġwould, Ġlike, Ġto, Ġchange, Ġthe, Ġelecti...   \n",
       "\n",
       "                                            aligned_tags  \n",
       "0      [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "1      [O, O, O, O, O, O, O, O, Position, Position, P...  \n",
       "2      [O, O, O, O, Position, Position, Position, Pos...  \n",
       "3      [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "4      [O, O, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "...                                                  ...  \n",
       "15589  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "15590  [Lead, Lead, Lead, Lead, Lead, Lead, Lead, Lea...  \n",
       "15591  [Position, Position, Position, Position, Posit...  \n",
       "15592  [Position, Position, Position, Position, Posit...  \n",
       "15593  [Position, Position, Position, Position, Posit...  \n",
       "\n",
       "[15594 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df.to_pickle('../data/preprocess_step2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
