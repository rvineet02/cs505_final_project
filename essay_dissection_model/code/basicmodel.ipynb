{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch \n",
    "from transformers import LongformerTokenizer\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = pd.read_pickle('../data/preprocess_step2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of token: 1764\n",
      "{'Claim', 'Evidence', 'Concluding Statement', 'Rebuttal', 'Position', 'O', 'Counterclaim', 'Lead'}\n"
     ]
    }
   ],
   "source": [
    "longest_list = max(tokenized_df['tokens'], key=len)\n",
    "print(\"Number of token:\", len(longest_list))\n",
    "\n",
    "\n",
    "all_labels = [item for sublist in tokenized_df['aligned_tags'] for item in sublist]\n",
    "unique_labels = set(all_labels)  \n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Text and Labels\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "labels = ['O', 'Claim', 'Evidence', 'Concluding Statement', 'Rebuttal', 'Position','Counterclaim', 'Lead', 'Padding']\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokenized_df['tokens']]\n",
    "input_labels = [[labels.index(l) for l in tags] for tags in tokenized_df['aligned_tags']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = len(longest_list) + 5\n",
    "\n",
    "def pad_sequences(sequences, max_len, padding_value=0):\n",
    "    return [seq + [padding_value] * (max_len - len(seq)) if len(seq) < max_len else seq[:max_len] for seq in sequences]\n",
    "\n",
    "padded_input_ids = pad_sequences(input_ids, MAX_LENGTH, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "padded_input_labels = pad_sequences(input_ids, MAX_LENGTH, padding_value=labels.index('Padding'))\n",
    "\n",
    "attention_masks = [[float(token_id != tokenizer.pad_token_id) for token_id in seq] for seq in padded_input_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "\n",
    "ds = EssayDataset(padded_input_ids, attention_masks, padded_input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "data_loader = DataLoader(ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
